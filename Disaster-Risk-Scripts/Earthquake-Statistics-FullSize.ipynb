{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c001e3d",
   "metadata": {},
   "source": [
    "### Earthquake intensity zone statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ab587b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Method ###\n",
    "\n",
    "##Output:\n",
    "# Provinces with population per earthquake risk column. \n",
    "# 5 earthquake risk columns\n",
    "# Shp or spatial database table\n",
    "\n",
    "##Input:\n",
    "# Province polygons\n",
    "# 5 earthquake risk columns\n",
    "# Shp or spatial database table\n",
    "\n",
    "##Input:\n",
    "# Province polygons\n",
    "# Earthquake polyons\n",
    "# Population raster\n",
    "\n",
    "## Steps:\n",
    "\n",
    "# 1.1\n",
    "# Clip province polygons by earthquake polygons\n",
    "# Explode polygons (multipart to single part)\n",
    "\n",
    "# 2.1\n",
    "# Extract population for each polygon using zonal statistics\n",
    "\n",
    "# 2.2\n",
    "# Extract building count for each polygon using spatial join and count\n",
    "\n",
    "# 2.3\n",
    "# Extract area for each polygon\n",
    "\n",
    "# 3.1\n",
    "# Summarize by both province, earthquake, building, area and intensity using pandas pivot table\n",
    "\n",
    "# 4.1\n",
    "# Join pivot table columns to original province polygons x3 (seperate for each dataset)\n",
    "\n",
    "# 5.1\n",
    "# QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0a2f1461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2 # required for exporting to postgis\n",
    "import rioxarray as rxr\n",
    "from rasterio.crs import CRS\n",
    "from sqlalchemy import create_engine\n",
    "import rasterstats\n",
    "from shapely.ops import transform\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "03190abd",
   "metadata": {},
   "source": [
    "### Setting connection and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "39b4f096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load database configuration from file\n",
    "with open(r'D:\\iMMAP\\code\\db_config\\hsdc_local_db_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Create database URL with credentials\n",
    "db_url = f\"postgresql://{config['username']}:{config['password']}@{config['host']}:{config['port']}/{config['database']}\"\n",
    "\n",
    "# Connect to the database\n",
    "con = create_engine(db_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6fe351f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b8e9da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define projection\n",
    "repro_crs = '+proj=cea'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b91650c0",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "512788be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Loading buildings   Start: 10:39:03\n",
      "    Loading buildings   End  : 10:43:56\n"
     ]
    }
   ],
   "source": [
    "pcode = 'reg_pcode' ### OBS: Adjust based on admin level\n",
    "\n",
    "#pop = r'D:\\iMMAP\\data\\Afghanistan\\Population\\WorldPop\\afg_worldpop_2020_UNadj_unconstrained.tif'\n",
    "#pop = r'C:\\Users\\VMO\\Desktop\\afg_worldpop_2020_UNadj_unconstrained_proj4326.tif'\n",
    "\n",
    "pop = r'D:\\iMMAP\\data\\Afghanistan\\afg_worldpop_2020_UNadj_unconstrained_projCEA.tif' #afg_worldpop_2020_UNadj_unconstrained_projCEA\n",
    "adm = gpd.GeoDataFrame.from_postgis('SELECT * from afg_admbnda_region', con).to_crs(repro_crs)\n",
    "#adm = gpd.read_file(r\"D:\\iMMAP\\data\\Afghanistan\\HSDC-Official\\afg_admbnda_adm1.shp\")#.to_crs(repro_crs)\n",
    "eq = gpd.read_file(r\"D:\\iMMAP\\data\\Afghanistan\\HSDC-Official\\afg_eq_hzda.shp\").to_crs(repro_crs)\n",
    "\n",
    "print('    Loading buildings   Start: {}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "build = gpd.GeoDataFrame.from_postgis('SELECT * from afg_buildings_microsoft_centroids', con).to_crs(repro_crs)\n",
    "print('    Loading buildings   End  : {}'.format(datetime.now().strftime(\"%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b1c1a52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Derived Projected CRS: +proj=cea +type=crs>\n",
       "Name: unknown\n",
       "Axis Info [cartesian]:\n",
       "- E[east]: Easting (metre)\n",
       "- N[north]: Northing (metre)\n",
       "Area of Use:\n",
       "- undefined\n",
       "Coordinate Operation:\n",
       "- name: unknown\n",
       "- method: Lambert Cylindrical Equal Area\n",
       "Datum: World Geodetic System 1984\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adm.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f63201af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Derived Projected CRS: +proj=cea +type=crs>\n",
       "Name: unknown\n",
       "Axis Info [cartesian]:\n",
       "- E[east]: Easting (metre)\n",
       "- N[north]: Northing (metre)\n",
       "Area of Use:\n",
       "- undefined\n",
       "Coordinate Operation:\n",
       "- name: unknown\n",
       "- method: Lambert Cylindrical Equal Area\n",
       "Datum: World Geodetic System 1984\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eq.crs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "907d5a70",
   "metadata": {},
   "source": [
    "### 1.1 Clip province polygons by earthquake polygons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "70bd9c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:43:56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VMO\\AppData\\Local\\Temp\\ipykernel_21140\\161707685.py:6: FutureWarning: Currently, index_parts defaults to True, but in the future, it will default to False to be consistent with Pandas. Use `index_parts=True` to keep the current behavior and True/False to silence the warning.\n",
      "  adm_eq = overlay.explode()\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Use the overlay function to clip admin polygons by earthquake zones\n",
    "overlay = gpd.overlay(adm, eq, how='intersection', keep_geom_type=None, make_valid=True)\n",
    "\n",
    "# Post-process\n",
    "adm_eq = overlay.explode()\n",
    "adm_eq = adm_eq.to_crs(repro_crs)\n",
    "adm_eq = adm_eq.reset_index()\n",
    "adm_eq = adm_eq.drop(columns=['level_1', 'level_0'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5be495e8",
   "metadata": {},
   "source": [
    "### 2.1 Extract population for each polygon using zonal statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4f1476e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:43:56\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Produce list of dictionaries, each dictionary representing the sum for one polygon\n",
    "zonalSt = rasterstats.zonal_stats(adm_eq, pop, stats = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b6d54b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:44:11\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Convert list of dictionaries to pandas dataframe (containing one column with each value)\n",
    "df = pd.DataFrame(zonalSt)\n",
    "df = df.rename(columns={'sum': 'pop_eq'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e9b66ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:44:11\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Add the values to the original table\n",
    "df_concat = pd.concat([df, adm_eq], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "399d8d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:44:11\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Convert table back into a geodataframe    \n",
    "gdf = gpd.GeoDataFrame(df_concat, geometry=df_concat.geometry) #wkb_geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7f2b79f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:44:11\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Reorder columns so population sum is last\n",
    "gdf_reordered_columns = gdf[[c for c in gdf if c not in ['pop_eq']] + ['pop_eq']]\n",
    "stats = gdf_reordered_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6a1c255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:44:12\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Set a new ID column\n",
    "stats = stats.reset_index(drop=True)\n",
    "stats = gdf.drop('id', axis=1)\n",
    "stats.insert(0, 'ID', range(len(gdf)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25012604",
   "metadata": {},
   "source": [
    "### 2.2 Extract building count for each polygon using spatial join and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e97475a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def drop_building_column(df):\n",
    "#    if 'build' in df.columns:\n",
    "#        df.drop('build', axis=1, inplace=True)\n",
    "#    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cfffef85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:44:12\n",
      "    Joining points to polygons   Start: 10:44:12\n",
      "    Joining points to polygons   Finish: 10:57:05\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Join building centroids to admin polygons\n",
    "print('    Joining points to polygons   Start: {}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "\n",
    "points = build\n",
    "polygons = stats\n",
    "\n",
    "#drop_building_column(polygons)\n",
    "\n",
    "# Joining the polygon attributes to each point\n",
    "# Creates a point layer of all buildings with the attributes copied from the interesecting polygon uniquely for each point\n",
    "joined_df = gpd.sjoin(\n",
    "    points,\n",
    "    polygons,\n",
    "    how='inner',\n",
    "    predicate='intersects')\n",
    "\n",
    "print('    Joining points to polygons   Finish: {}'.format(datetime.now().strftime(\"%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb8d4137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Counting number of buildings          Start: 10:57:05\n",
      "    Counting number of buildings          End:   10:57:05\n"
     ]
    }
   ],
   "source": [
    "# Count number of buildings within admin polygons (i.e. group by adm code)\n",
    "print('    Counting number of buildings          Start: {}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "\n",
    "build_count = joined_df.groupby(\n",
    "    ['ID'],\n",
    "    as_index=False,\n",
    ")['geom'].count() # column is arbitrary\n",
    "\n",
    "# Change column name to build_count\n",
    "build_count.rename(columns = {'geom': 'bld_eq'}, inplace = True)\n",
    "\n",
    "print('    Counting number of buildings          End:   {}'.format(datetime.now().strftime(\"%H:%M:%S\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6b628ade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:57:05\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Merge build count back on to admin dataset\n",
    "polygons = polygons.merge(\n",
    "    build_count, \n",
    "    on=['ID'], \n",
    "    how='left')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "946de8ef",
   "metadata": {},
   "source": [
    "### 2.3 Extract area for each polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b5ca9d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:57:05\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "polygons['km2_eq'] = polygons['geometry'].area.div(1000000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92c271f8",
   "metadata": {},
   "source": [
    "### 3.1 Summarize by both province and earthquake intensity using pandas pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ffe6fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:57:05\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# pivot table to sum population by admin and intensity\n",
    "pivoted = pd.pivot_table(polygons, values=['pop_eq','bld_eq', 'km2_eq'], index=pcode, columns='intensity', aggfunc='sum')\n",
    "\n",
    "# fill NaN values with 0\n",
    "pivoted.fillna(0, inplace=True)\n",
    "\n",
    "# reset index to make admin a column again\n",
    "pivoted = pivoted.reset_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd84934d",
   "metadata": {},
   "source": [
    "### 4.1 Join pivot table columns to original province polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b4e343ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:57:05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VMO\\anaconda3\\envs\\earth2\\lib\\site-packages\\geopandas\\geodataframe.py:1470: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (1 levels on the left, 2 on the right)\n",
      "  result = DataFrame.merge(self, *args, **kwargs)\n",
      "c:\\Users\\VMO\\anaconda3\\envs\\earth2\\lib\\site-packages\\geopandas\\geodataframe.py:1470: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  result = DataFrame.merge(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "eq_stats = adm.merge(\n",
    "            pivoted, \n",
    "            on=pcode, \n",
    "            how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5843c107",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_stats.rename(columns=lambda x: x[0] + '_' + str(x[1]) if isinstance(x, tuple) and isinstance(x[1], int) else x, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d37328f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1_eq_stats = eq_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a6c5429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which is the first pop_eq column that exists in the dataset\n",
    "\n",
    "def get_first_column_startswith(df, prefix):\n",
    "    for column in df.columns:\n",
    "        if column.startswith(prefix):\n",
    "            return column\n",
    "    return None\n",
    "\n",
    "prefix_pop = 'pop_eq'\n",
    "prefix_build = 'bld_eq'\n",
    "prefix_km2 = 'km2_eq'\n",
    "\n",
    "first_column_pop = get_first_column_startswith(eq_stats, prefix_pop)\n",
    "first_column_build = get_first_column_startswith(eq_stats, prefix_build)\n",
    "first_column_km2 = get_first_column_startswith(eq_stats, prefix_km2)\n",
    "\n",
    "#print(f\"First column starting with '{prefix}': {first_column_pop}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bb18f9d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:57:06\n",
      "Converted population figures\n",
      "Converted building figures\n",
      "Rounded area figures\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Convert pop figures to int\n",
    "eq_stats.loc[:,first_column_pop:'pop_eq_10'] = eq_stats.loc[:,first_column_pop:'pop_eq_10'].astype(int)\n",
    "print('Converted population figures')\n",
    "\n",
    "# Convert building figures to int\n",
    "eq_stats.loc[:,first_column_build:'bld_eq_10'] = eq_stats.loc[:,first_column_build:'bld_eq_10'].astype(int)\n",
    "print('Converted building figures')\n",
    "\n",
    "# Round area figures to 2 decimal places\n",
    "eq_stats.loc[:,first_column_km2:'km2_eq_10'] = eq_stats.loc[:,first_column_km2:'km2_eq_10'].round(1)\n",
    "print('Rounded area figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c4e098c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:57:06\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Reprojet back to 4326\n",
    "eq_stats = eq_stats.to_crs('epsg:4326')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "359506c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:57:06\n"
     ]
    }
   ],
   "source": [
    "print('{}'.format(datetime.now().strftime(\"%H:%M:%S\")))\n",
    "# Save output to database\n",
    "eq_stats.to_postgis('afg_admbnda_region_eq_stats_v02', con, if_exists='replace')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
